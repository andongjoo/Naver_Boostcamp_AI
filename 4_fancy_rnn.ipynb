{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_fancy_rnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfjERFbSN/ABhUW/ypjMjf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oLHN0S-UYgR"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "from torch import nn\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "import torch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcDPCJngUZgM"
      },
      "source": [
        "vocab_size = 100\r\n",
        "pad_id = 0\r\n",
        "\r\n",
        "data = [\r\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\r\n",
        "  [62,76,79,66,32],\r\n",
        "  [93,77,16,67,46,74,24,70],\r\n",
        "  [19,83,88,22,57,40,75,82,4,46],\r\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\r\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\r\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\r\n",
        "  [94,21,79,24,3,86],\r\n",
        "  [80,80,33,63,34,63],\r\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\r\n",
        "]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpA6kWKfUeRI",
        "outputId": "5fc1e7fa-37b0-4875-b2d2-16a26e862bb6"
      },
      "source": [
        "max_len = len(max(data, key=len))\r\n",
        "print(f\"Maximum sequence length: {max_len}\")\r\n",
        "\r\n",
        "valid_lens = []\r\n",
        "for i, seq in enumerate(tqdm(data)):\r\n",
        "  valid_lens.append(len(seq))\r\n",
        "  if len(seq) < max_len:\r\n",
        "    data[i] = seq + [pad_id] * (max_len - len(seq))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 4438.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ4dhfOPUe4O",
        "outputId": "a01e727e-3d5e-47d3-cf93-fc03ccaafa0a"
      },
      "source": [
        "# B: batch size, L: maximum sequence length\r\n",
        "batch = torch.LongTensor(data)  # (B, L)\r\n",
        "batch_lens = torch.LongTensor(valid_lens)  # (B)\r\n",
        "\r\n",
        "batch_lens, sorted_idx = batch_lens.sort(descending=True)\r\n",
        "batch = batch[sorted_idx]\r\n",
        "\r\n",
        "print(batch)\r\n",
        "print(batch_lens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCpRkVh7Ue8A"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7YFchOpUe-x"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQl6npa8UlHf"
      },
      "source": [
        "LSTM에선 cell state가 추가된다.  \r\n",
        "Cell state의 shape는 hidden state와 동일함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YWuzoEwUfBJ"
      },
      "source": [
        "embedding_size = 256\r\n",
        "hidden_size = 512\r\n",
        "num_layers = 1\r\n",
        "num_dirs = 1\r\n",
        "\r\n",
        "embedding = nn.Embedding(vocab_size, embedding_size)\r\n",
        "lstm = nn.LSTM(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")\r\n",
        "\r\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\r\n",
        "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgDkL_9OUfFo",
        "outputId": "dbcfe0cf-1249-4454-e928-3cef40bfb88b"
      },
      "source": [
        "# d_w: word embedding size\r\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\r\n",
        "\r\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n",
        "\r\n",
        "packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\r\n",
        "print(packed_outputs)\r\n",
        "print(packed_outputs[0].shape)\r\n",
        "print(h_n.shape)\r\n",
        "print(c_n.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-0.0392, -0.0685,  0.0425,  ...,  0.0365,  0.0173,  0.1236],\n",
            "        [ 0.0463,  0.0884, -0.0316,  ..., -0.0130,  0.0566, -0.1179],\n",
            "        [-0.0991,  0.1103, -0.0499,  ...,  0.0419, -0.0030,  0.1472],\n",
            "        ...,\n",
            "        [-0.1116, -0.0279, -0.0413,  ...,  0.1496,  0.0085, -0.0505],\n",
            "        [-0.0312, -0.0199, -0.1851,  ...,  0.0510, -0.0223, -0.1211],\n",
            "        [-0.1257,  0.0674, -0.2548,  ...,  0.0144, -0.1123, -0.1160]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 512])\n",
            "torch.Size([1, 10, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxQV6VyCUfHo",
        "outputId": "26cfe7ab-e2b8-48d7-b849-5e9607282405"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n",
        "print(outputs.shape)\r\n",
        "print(output_lens)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et-updQHUfJs"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIA12o6LUfLt"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgUNtwutUfPa"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfvJgRthUfRe"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOOhYAg9Uuen"
      },
      "source": [
        "GRU는 cell state가 없어 RNN과 동일하게 사용 가능.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKxIy4eRUzCC"
      },
      "source": [
        "gru = nn.GRU(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPy2AekmUzPT"
      },
      "source": [
        "output_layer = nn.Linear(hidden_size, vocab_size)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3n2mCVaUzTX"
      },
      "source": [
        "input_id = batch.transpose(0, 1)[0, :]  # (B)\r\n",
        "hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-P0XakcUzWz"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N967q_nGUzaO",
        "outputId": "7d55eec4-8cb8-4b9a-eaac-d49c30e974a0"
      },
      "source": [
        "for t in range(max_len):\r\n",
        "  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\r\n",
        "  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\r\n",
        "\r\n",
        "  # V: vocab size\r\n",
        "  output = output_layer(output)  # (1, B, V)\r\n",
        "  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\r\n",
        "\r\n",
        "  print(\"*\" * 50)\r\n",
        "  print(f\"Time step: {t}\")\r\n",
        "  print(output.shape)\r\n",
        "  print(probs.shape)\r\n",
        "  print(top_id.shape)\r\n",
        "\r\n",
        "  input_id = top_id.squeeze(0)  # (B)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Time step: 0\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 1\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 2\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 3\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 4\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 5\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 6\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 7\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 8\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 9\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 10\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 11\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 12\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 13\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 14\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 15\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 16\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 17\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 18\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 19\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXEo4LkvUzjl"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e9YPoskdwKK"
      },
      "source": [
        "num_layers = 2\r\n",
        "num_dirs = 2\r\n",
        "dropout=0.1\r\n",
        "\r\n",
        "gru = nn.GRU(\r\n",
        "    input_size=embedding_size,\r\n",
        "    hidden_size=hidden_size,\r\n",
        "    num_layers=num_layers,\r\n",
        "    dropout=dropout,\r\n",
        "    bidirectional=True if num_dirs > 1 else False\r\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p0TYS0aiVxp",
        "outputId": "e782d20d-b95b-441c-e6ff-aac2591a6dc2"
      },
      "source": [
        "# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\r\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\r\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\r\n",
        "\r\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n",
        "\r\n",
        "packed_outputs, h_n = gru(packed_batch, h_0)\r\n",
        "print(packed_outputs)\r\n",
        "print(packed_outputs[0].shape)\r\n",
        "print(h_n.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-0.1326, -0.1133,  0.0575,  ..., -0.1235, -0.2385, -0.0998],\n",
            "        [ 0.0415, -0.1123,  0.0882,  ..., -0.3231,  0.1095, -0.0960],\n",
            "        [-0.0565, -0.0108,  0.0508,  ..., -0.1299, -0.1788,  0.2286],\n",
            "        ...,\n",
            "        [ 0.0924, -0.0133, -0.0159,  ..., -0.0206, -0.0354,  0.1148],\n",
            "        [-0.0016, -0.0329, -0.0191,  ...,  0.0677,  0.1297,  0.0719],\n",
            "        [ 0.0957,  0.0884,  0.0226,  ..., -0.0758,  0.0945,  0.1168]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 1024])\n",
            "torch.Size([4, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9vwK-9FiV8C",
        "outputId": "bfb7f80e-b4ab-4ed1-a9b4-c73433fd8760"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n",
        "\r\n",
        "print(outputs.shape)  # (L, B, num_dirs*d_h)\r\n",
        "print(output_lens)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 1024])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgBTn13Zifeb",
        "outputId": "6ec47e4b-ecc8-4539-81a5-47dbe4995734"
      },
      "source": [
        "batch_size = h_n.shape[1]\r\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\r\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-9.1026e-02, -1.0278e-02, -2.7807e-02,  ..., -2.5467e-01,\n",
            "            9.0805e-02, -2.9887e-01],\n",
            "          [-3.2203e-01, -1.5691e-01, -7.8042e-02,  ...,  1.6917e-02,\n",
            "            2.8825e-02, -9.9215e-02],\n",
            "          [ 1.1382e-01,  4.3200e-02,  8.5352e-02,  ..., -2.3069e-01,\n",
            "           -1.2750e-01, -6.8493e-02],\n",
            "          ...,\n",
            "          [-2.8935e-02, -1.7448e-01, -1.1029e-01,  ..., -5.0516e-02,\n",
            "           -1.3285e-01, -1.6866e-02],\n",
            "          [ 7.0222e-02,  2.5313e-01,  1.2931e-01,  ...,  2.2693e-01,\n",
            "            1.3067e-01,  1.4080e-01],\n",
            "          [-1.6766e-01,  6.1143e-02, -2.0992e-01,  ...,  4.7271e-01,\n",
            "            3.1898e-01, -2.1612e-01]],\n",
            "\n",
            "         [[-1.8661e-01,  1.9973e-01,  4.4802e-03,  ..., -1.3788e-01,\n",
            "            1.7002e-01, -2.2979e-01],\n",
            "          [-1.4153e-01,  1.2149e-01, -1.4634e-02,  ...,  7.1073e-02,\n",
            "            1.9671e-01,  2.4339e-01],\n",
            "          [-4.8052e-01, -3.8710e-01, -5.1994e-02,  ...,  3.7520e-01,\n",
            "            9.7189e-02,  2.1683e-01],\n",
            "          ...,\n",
            "          [ 3.6767e-01,  2.9397e-02, -3.2795e-01,  ..., -1.7988e-01,\n",
            "           -4.6061e-02,  6.6074e-02],\n",
            "          [ 9.0263e-02,  2.2287e-02,  3.5587e-01,  ..., -6.6038e-02,\n",
            "            1.8213e-01, -1.0526e-01],\n",
            "          [ 3.4620e-01, -3.4275e-01, -2.3380e-01,  ..., -9.6121e-02,\n",
            "           -2.0047e-01, -2.5818e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5680e-02,  8.8434e-02,  2.2564e-02,  ..., -1.3875e-01,\n",
            "            2.0192e-01, -5.0370e-02],\n",
            "          [ 7.9356e-03,  2.8792e-02, -1.9250e-02,  ...,  1.8193e-01,\n",
            "            4.2514e-02,  7.1675e-02],\n",
            "          [ 9.2379e-02, -1.3343e-02, -1.5905e-02,  ..., -4.8674e-02,\n",
            "           -3.9486e-02,  4.0068e-02],\n",
            "          ...,\n",
            "          [ 3.8652e-02,  6.3678e-02, -3.1197e-01,  ...,  9.0345e-02,\n",
            "            1.5261e-01, -2.6872e-02],\n",
            "          [ 1.9137e-01, -8.8932e-02,  2.6549e-01,  ..., -1.3863e-01,\n",
            "           -1.2724e-01,  3.5779e-01],\n",
            "          [ 1.1737e-01, -2.6545e-02, -2.2196e-02,  ...,  1.2447e-01,\n",
            "           -8.4651e-03, -1.3677e-01]],\n",
            "\n",
            "         [[-1.9953e-01, -6.5979e-02, -1.2082e-01,  ..., -1.2352e-01,\n",
            "           -2.3851e-01, -9.9836e-02],\n",
            "          [ 6.9059e-02, -4.7150e-02,  1.5079e-01,  ..., -3.2314e-01,\n",
            "            1.0950e-01, -9.6029e-02],\n",
            "          [ 1.0764e-02,  3.0742e-02, -1.4883e-02,  ..., -1.2989e-01,\n",
            "           -1.7881e-01,  2.2860e-01],\n",
            "          ...,\n",
            "          [ 2.5595e-01,  1.4097e-01, -2.7648e-01,  ...,  1.4109e-01,\n",
            "           -2.5023e-02, -5.6364e-02],\n",
            "          [-2.9534e-01,  1.0038e-01, -6.3232e-02,  ..., -1.3193e-01,\n",
            "            1.5714e-01,  1.2335e-01],\n",
            "          [-1.5499e-02, -1.2165e-01, -1.8251e-04,  ..., -7.1540e-02,\n",
            "            1.6430e-01, -9.5401e-02]]]], grad_fn=<ViewBackward>)\n",
            "torch.Size([2, 2, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}